#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„CDNä¸Šä¼ è„šæœ¬ - åªä¸Šä¼ å¤§æ–‡ä»¶ï¼Œæ’é™¤å­—ä½“å’ŒPDF.js
"""
import os
import boto3
from pathlib import Path

def upload_large_files_only():
    """åªä¸Šä¼ å¤§å›¾ç‰‡å’ŒPDFæ–‡ä»¶åˆ°CDN"""
    
    # é…ç½®
    s3_client = boto3.client(
        's3',
        endpoint_url='https://447991a9c9d7dad31c67040315d483b2.r2.cloudflarestorage.com',
        aws_access_key_id='15f81283b1e9092dc433661173e17caa',
        aws_secret_access_key='0a92b00e366dcd0923743da7c8e5b4680d83af1b45cfa114160a77309aafeb79',
        region_name='auto'
    )
    
    bucket_name = 'cuhkstudy'
    base_path = Path('/var/www/cuhkstudy/public')
    
    # è¦ä¸Šä¼ çš„æ–‡ä»¶ç±»å‹å’Œå¤§å°é™åˆ¶
    upload_rules = [
        {'pattern': '*.png', 'min_size': 1024*1024},  # PNG > 1MB
        {'pattern': '*.jpg', 'min_size': 500*1024},   # JPG > 500KB  
        {'pattern': '*.jpeg', 'min_size': 500*1024},  # JPEG > 500KB
        {'pattern': '*.pdf', 'min_size': 0},          # æ‰€æœ‰PDF
    ]
    
    uploaded_files = []
    
    for rule in upload_rules:
        pattern = rule['pattern']
        min_size = rule['min_size']
        
        for file_path in base_path.rglob(pattern):
            # è·³è¿‡PDF.jsç›¸å…³æ–‡ä»¶
            if 'pdfjs' in str(file_path):
                continue
                
            file_size = file_path.stat().st_size
            if file_size >= min_size:
                relative_path = file_path.relative_to(base_path)
                s3_key = str(relative_path)
                
                try:
                    s3_client.upload_file(
                        str(file_path), 
                        bucket_name, 
                        s3_key,
                        ExtraArgs={'ContentType': get_content_type(file_path)}
                    )
                    uploaded_files.append({
                        'file': s3_key,
                        'size': f"{file_size/1024/1024:.1f}MB"
                    })
                    print(f"âœ… å·²ä¸Šä¼ : {s3_key} ({file_size/1024/1024:.1f}MB)")
                except Exception as e:
                    print(f"âŒ ä¸Šä¼ å¤±è´¥: {s3_key} - {e}")
    
    print(f"\nğŸ“Š ä¸Šä¼ æ€»ç»“: å…±ä¸Šä¼  {len(uploaded_files)} ä¸ªå¤§æ–‡ä»¶")
    total_size = sum(float(f['size'].replace('MB', '')) for f in uploaded_files)
    print(f"ğŸ“ æ€»å¤§å°: {total_size:.1f}MB")
    
    return uploaded_files

def get_content_type(file_path):
    """è·å–æ–‡ä»¶MIMEç±»å‹"""
    suffix = file_path.suffix.lower()
    content_types = {
        '.png': 'image/png',
        '.jpg': 'image/jpeg', 
        '.jpeg': 'image/jpeg',
        '.pdf': 'application/pdf'
    }
    return content_types.get(suffix, 'application/octet-stream')

if __name__ == "__main__":
    upload_large_files_only()
